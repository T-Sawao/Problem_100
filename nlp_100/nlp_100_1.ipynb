{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intended-affairs",
   "metadata": {},
   "source": [
    "# 【言語処理100本ノック 2020】第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-offense",
   "metadata": {},
   "source": [
    "### 00. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arranged-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"stressed\"\n",
    "a[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-halloween",
   "metadata": {},
   "source": [
    "### 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fleet-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"パタトクカシーー\"\n",
    "q[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-hartford",
   "metadata": {},
   "source": [
    "### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"パトカー\"\n",
    "b = \"タクシー\"\n",
    "\n",
    "''.join(x+y for x, y in zip(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-madness",
   "metadata": {},
   "source": [
    "### 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eaa8c2b-ba91-425b-b6f9-795cba34dac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "text = re.sub(\"[,\\.]\", \"\", text)\n",
    "text_list = text.split(\" \")\n",
    "kazu_list = [len(text) for text in text_list]\n",
    "kazu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-anger",
   "metadata": {},
   "source": [
    "### 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7748f0-9441-4f31-b30c-4104452e4695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 3, 'Li': 4, 'Be': 5, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 11, 'Na': 12, 'Mi': 13, 'Al': 14, 'Si': 15, 'P': 15, 'S': 16, 'Cl': 18, 'Ar': 19, 'K': 19, 'Ca': 21}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "text = re.sub(\"[,\\.]\", \"\", text)\n",
    "text_list = text.split()\n",
    "a = np.array([1, 5, 6, 7, 8, 9, 15, 16, 19])\n",
    "\n",
    "text_dict = {}\n",
    "for i, word in enumerate(text_list):\n",
    "    if i+1  in a:\n",
    "        text_dict[word[:1]] = i+1\n",
    "    else:\n",
    "        text_dict[word[:2]] = i+2\n",
    "        \n",
    "print(text_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a423302-700e-45bc-a6c5-40e011f6f90e",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee549d57-79f1-46b3-9343-b4e8c9c32cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語:[('I', 'am'), ('am', 'an'), ('an', 'NLPer')]\n",
      "文字:[('I', ' '), (' ', 'a'), ('a', 'm'), ('m', ' '), (' ', 'a'), ('a', 'n'), ('n', ' '), (' ', 'N'), ('N', 'L'), ('L', 'P'), ('P', 'e'), ('e', 'r')]\n"
     ]
    }
   ],
   "source": [
    "# split()で単語化。\n",
    "# 文字化\n",
    "# オリジナル関数を作成\n",
    "\n",
    "def n_gram(n, text):\n",
    "    return list(zip(*[text[i:] for i in range(n)]))\n",
    "\n",
    "z = \"I am an NLPer\"\n",
    "word = n_gram(2, z.split())\n",
    "letter = n_gram(2, z)\n",
    "\n",
    "print(f\"単語:{word}\")\n",
    "print(f\"文字:{letter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e83d9-ef72-44d0-8ea0-abf5550cc340",
   "metadata": {},
   "source": [
    "### 06. 集合  \n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfd386b-d167-4d7d-9944-28bb45ddc192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合:{('p', 'a'), ('i', 's'), ('s', 'e'), ('p', 'h'), ('a', 'p'), ('r', 'a'), ('d', 'i'), ('g', 'r'), ('a', 'd'), ('a', 'g'), ('a', 'r')}\n",
      "積集合:{('p', 'a'), ('r', 'a'), ('a', 'p'), ('a', 'r')}\n",
      "差集合:{('i', 's'), ('d', 'i'), ('s', 'e'), ('a', 'd')}\n",
      "xにseがあるか True\n",
      "yにseがあるか False\n"
     ]
    }
   ],
   "source": [
    "a = \"paraparaparadise\"\n",
    "b = \"paragraph\"\n",
    "\n",
    "x = set(n_gram(2, a))\n",
    "y = set(n_gram(2, b))\n",
    "\n",
    "print(f\"和集合:{x | y}\")\n",
    "print(f\"積集合:{x & y}\")\n",
    "print(f\"差集合:{x - y}\")\n",
    "print(\"xにseがあるか\",{(\"s\", \"e\")} <= x)\n",
    "print(\"yにseがあるか\",{(\"s\", \"e\")} <= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc03e2-edd7-48b0-a6f2-763fa5de5545",
   "metadata": {},
   "source": [
    "### 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9babc7-7a96-4294-a047-256a404d917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "x=12\n",
    "y=\"気温\"\n",
    "z=22.4\n",
    "\n",
    "def kion(hour, title, x):\n",
    "    print(f\"{hour}時の{title}は{x}\")\n",
    "\n",
    "kion(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3022e-320e-48f5-a404-294e528a19a7",
   "metadata": {},
   "source": [
    "### 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ.  \n",
    "英小文字ならば(219 - 文字コード)の文字に置換  \n",
    "その他の文字はそのまま出力  \n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "150a3e73-07bc-4d47-a168-a4a756c778a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号化: gsv jfrxp yildm ulc qfnkh levi gsv ozab wlt\n",
      "復号化: the quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "def cipher(str):\n",
    "  rep = [chr(219 - ord(x)) if x.islower() else x for x in str]\n",
    "\n",
    "  return ''.join(rep)\n",
    "\n",
    "message = 'the quick brown fox jumps over the lazy dog'\n",
    "message = cipher(message)\n",
    "print('暗号化:', message)\n",
    "message = cipher(message)\n",
    "print('復号化:', message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00cbdd6e-0e61-47dc-980c-b8960db7049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号化 I xzm wl rg 2021\n",
      "復号化 I can do it 2021\n"
     ]
    }
   ],
   "source": [
    "str = 'I can do it 2021'\n",
    "\n",
    "def cipher(str):\n",
    "    list = [chr(219 - ord(x)) if x.islower() else x for x in str]\n",
    "    return ''.join(list)\n",
    "\n",
    "message = cipher(str)\n",
    "print(\"暗号化\", message)\n",
    "message = cipher(message)\n",
    "print(\"復号化\", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d308c-87b4-4702-ba76-0137f9199990",
   "metadata": {},
   "source": [
    "### 09. Typoglycemia\n",
    "\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．  \n",
    "ただし，長さが４以下の単語は並び替えないこととする．  \n",
    "適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "51c7268d-04d1-4404-bdd6-1be7cbdb041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2 µs ± 27.4 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# 単語列を分断する(先頭、中央、末尾）  \n",
    "# 中央をランダムに並び替える\n",
    "# ※ifで4文字以上を対象にし、それ以外はそのまま。\n",
    "# 文章をfor文でスペース区切りにする。\n",
    "import random\n",
    "\n",
    "text = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "def shuffle(text):\n",
    "    text_new = []\n",
    "    for word in text.split(\" \"):\n",
    "        if len(word) > 4:\n",
    "            lead = word[0]\n",
    "            last = word[-1]\n",
    "            middle = word[1:-1]\n",
    "            middle_random = random.sample(middle, len(word) -2)\n",
    "            text_new.append(lead + ''.join(middle_random) + last)\n",
    "        else:\n",
    "            text_new.append(word)\n",
    "\n",
    "    return ' '.join(text_new)\n",
    "\n",
    "shuffle(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
