---
title: "第10章：机器翻译"
date: 2020-09-12 18:00:00 +0800
layout: single
toc: true
lang: zh
sidebar: {nav: "sidebar_zh"}
header:
  teaser: /assets/images/ch10.png
---


在本章中，我们训练一个神经机器翻译（NMT, Neural Machine Translation）模型。对于英语-德语翻译任务，可以使用IWSLT'14英德数据集；对于日语-英语翻译任务，可以使用[京都フリー翻訳タスク（KFTT）](http://www.phontron.com/kftt/index-ja.html)数据集。 构建NMT模型时，请活用既存的工具框架，如[fairseq](https://github.com/pytorch/fairseq)，[Hugging Face Transformers](https://github.com/huggingface/transformers)或[OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)。



## 90. 数据预处理


下载数据集，按需对其进行词分割（tokenize）等预处理，之后将其分为训练集、验证集与测试集。对于英语-德语翻译任务，可以直接使用[预处理脚本](https://github.com/nlp100/nlp100.github.io/blob/master/tools/prepare_mt_data.sh)。对于日语-英语翻译任务，日语使用语素（Morpheme）、英语使用单词作为分词（token）的基本单位。


## 91. 训练机器翻译模型

使用第90问中的数据集训练机器翻译模型（选取适当的模型架构，如基于LSTM的模型，基于Transformer的模型等）。

## 92. 使用翻译模型

编写程序，以使用第91问中训练所得的翻译模型，将给定的任意源语言句子（英语、日语）翻译为目标语言（德语、英语）。

## 93. BLEU分数

计算第91问中训练所得的模型在测试集上的BLEU分数。

## 94. 束搜索 (Beam search)

使用第91问中训练所得的模型翻译句子时，采用束搜索（Beam search）进行解码。在1到100之间变换束大小（beam size），绘制BLEU分数随束大小变化的折线图。

## 95. 子字（Subword）

以子字（subword）取代单词（word），作为词分割（tokenize）的基本单位。使用这种新的表示法，重复第91-94问的实验。


## 96. 学习过程可视化

使用[TensorBoard](https://www.tensorflow.org/tensorboard)等工具，可视化机器翻译模型的训练过程。 具体地，可视化模型在训练集、验证集上的损失与BLEU分数等关键指标。

## 97. 超参数调整

更改模型的架构和/或超参数，找到能够在验证集上达到最高性能的模型与超参数设定。

## 98. 领域自适应


对于英语-德语翻译任务，使用[sacreBLEU](https://github.com/mjpost/sacreBLEU)工具在newstest2014数据集上评估机器翻译模型，然后活用[News Commentary](http://data.statmt.org/news-commentary/v15/training/news-commentary-v15.de-en.tsv.gz)数据集，尝试改善模型在目标域的翻译性能。

对于日语-英语翻译任务，使用[Japanese-English Subtitle Corpus (JESC)](https://nlp.stanford.edu/projects/jesc/index_ja.html)或[JParaCrawl](http://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/)等数据集，尝试改善模型在KFTT测试集上的翻译性能。


## 99. 构建翻译系统

构建一个demo系统，使用户能够在浏览器页面中输入文本，并得到其翻译结果。