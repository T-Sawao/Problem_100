---
title: "第6章: 机器学习"
date: 2020-09-04 12:00:00 +0800
layout: single
toc: true
lang: zh
sidebar: {nav: "sidebar_zh"}
header:
  teaser: /assets/images/ch06.png
---

在本章中，我们使用由Fabio Gasparetti公开的数据集[News Aggregator Data Set](https://archive.ics.uci.edu/ml/datasets/News+Aggregator)，以解决新闻分类的任务。给定新闻的标题，该任务旨在将其正确归类为"Business"，"Science"， "Entertainment"或"Health"。


## 50. 下载并预处理数据集

下载数据集[News Aggregator Data Set](https://archive.ics.uci.edu/ml/datasets/News+Aggregator)，并按下列要求创建训练集 (`train.txt`)、验证集 (`valid.txt`) 及测试集 (`test.txt`)：

1. 解压已下载的zip压缩包，并阅读`readme.txt`；
2. 提取由 "Reuters"，"Huffington Post"，"Businessweek"，"Contactmusic.com" 及"Daily Mail"所出版的文章语料；
3. 随机打乱所提取出的实例（即文章）的顺序；
4. 以训练集占80%、验证集占10%、测试集占10%的比例分割所提取出的语料，然后分别存储至文件`train.txt`，`valid.txt`和`test.txt`。文件中，每行记录一个实例，每个实例记录该实例所属的类别与文章的标题，二者之间以制表符（TAB）分隔。

完成数据集的创建后，检查每个类别下实例的数量。

## 51. 特征抽取

自由设计若干用于分类的特征。分别从训练集、验证集和测试集中抽取这些特征，并将结果存储至文件`train.feature.txt`, `valid.feature.txt` 和 `test.feature.txt`。设计特征时，可以考虑将文章的标题拆分成为单词的列表，作为最简单的基线（baseline）。

## 52. 训练

使用第51问所创建的训练数据，训练逻辑回归（logistic regression）模型。

## 53. 预测

编写一个程序，使其满足以下要求：
+ 接收文章的标题作为输入；
+ 利用第52问所创建的逻辑回归模型，根据所输入的文章标题，预测该文章所属的类别；
+ 返回所预测的类别及该预测的概率作为输出。

## 54. 正确率计算

计算第52问所得的逻辑回归模型在训练集和测试集上的预测正确率（accuracy）。

## 55. 创建混淆矩阵

计算第52问所得的逻辑回归模型在训练集和测试集上的混淆矩阵（confusion matrix）。

## 56. 准确率(Precision)，召回率(Recall)，F1分数(F1 score)

按下列步骤计算第52问所得的逻辑回归模型在测试集上的准确率（Precision）、召回率（Recall）及F1分数（F1 score）。
1. 对于所有类别（"Business"、"Science"、 "Entertainment"及"Health"），分别计算模型的准确率、召回率及F1分数；
2. 对所有类别的准确率，召回率及F1分数取微平均（micro-average）与宏平均（macro-average），以计算总体的准确率、召回率及F1分数。

## 57. 特征权重确认

列出第52问所得的逻辑回归模型中权重值（weight）最大的10个特征与权重值最小的10个特征。

## 58. 正则化

训练逻辑回归模型时，可以通过调整正则化参数抑制过拟合（overfitting）现象的产生。 使用不同的正则化参数训练逻辑回归模型，并在训练集、验证集与测试集上计算模型的正确率。以`x`轴为正则化参数、`y`轴为对应的正确率，绘制折线图。


## 59. 超参数调节

改变优化算法和/或参数，重新训练分类模型，找出在验证集上正确率最高的优化算法与参数。使用该优化算法与参数训练模型后，计算所得模型在测试集上的正确率。
